{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====== Nguồn http://users.soict.hust.edu.vn/khoattq/ml-dm-course/ ======\n",
    "\n",
    "\n",
    "# Bài toán phân loại sử dụng SVM \n",
    "\n",
    "Mục tiêu: \n",
    "- Xây dựng được mô hình svm sử dụng thư viện sklearn. \n",
    "- Ứng dụng, hiểu cách áp dụng mô hình SVM vào giải quyết bài toán thực tế (Ví dụ: phân loại văn bản) \n",
    "- Sử dụng độ đo Accuracy để làm độ đo đánh giá chất lượng mô hình. \n",
    "\n",
    "Dữ liệu: \n",
    "- Có tập các văn bản và nhãn tương ứng của từng văn bản trong một khoảng thời gian \n",
    "- Tập các nhãn (10 nhãn khác nhau): \n",
    "    > Giải trí, Khoa học - Công nghệ, Kinh tế, Pháp luật, Sức khỏe, Thể thao, Thời sự, Tin khác, Độc giả, Đời sống - Xã hội\n",
    "- Ví dụ văn bản nhãn **thể thao**: \n",
    "    > \"Dân_trí Real Madrid đã dẫn trước trong cả trận đấu , nhưng họ vẫn phải chấp_nhận bị Dortmund cầm hòa 2-2 ở Bernabeu . Real Madrid chấp_nhận đứng thứ_hai ở bảng F Champions League ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dữ liệu từ thư mục đã thu thập từ trước \n",
    "\n",
    "Giả sử cấu trúc thư mục như sau \n",
    "\n",
    "- data/news_1135/\n",
    "\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng văn bản    Nhãn                          \n",
      "---------------------------------------------\n",
      "122                 doi-song                      \n",
      "57                  du-lich                       \n",
      "196                 giai-tri                      \n",
      "118                 giao-duc                      \n",
      "133                 khoa-hoc                      \n",
      "229                 kinh-doanh                    \n",
      "26                  phap-luat                     \n",
      "193                 suc-khoe                      \n",
      "177                 the-thao                      \n",
      "58                  thoi-su                       \n",
      "---------------------------------------------\n",
      "Tổng số văn bản: 1309\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"data/news_vnexpress/\"\n",
    "header = \"%-20s%-30s\" % (\"Số lượng văn bản\", \"Nhãn\")\n",
    "print(header)\n",
    "print(\"---------------------------------------------\")\n",
    "total = 0\n",
    "for label in os.listdir(DATA_PATH):\n",
    "    n = len(os.listdir(os.path.join(DATA_PATH, label)))\n",
    "    total += n\n",
    "    entry = \"%-20d%-30s\" % (n, label)\n",
    "    print(entry)\n",
    "print(\"---------------------------------------------\")\n",
    "print(f'Tổng số văn bản: {total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'filenames', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "data_train = load_files(container_path=DATA_PATH, encoding=\"utf-8\")\n",
    "print(dir(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID     Nhãn      \n",
      "---------------------------------------------\n",
      "0      doi-song  \n",
      "1      du-lich   \n",
      "2      giai-tri  \n",
      "3      giao-duc  \n",
      "4      khoa-hoc  \n",
      "5      kinh-doanh\n",
      "6      phap-luat \n",
      "7      suc-khoe  \n",
      "8      the-thao  \n",
      "9      thoi-su   \n"
     ]
    }
   ],
   "source": [
    "header = \"%-6s %-10s\" % (\"ID\", \"Nhãn\")\n",
    "print(header)\n",
    "print(\"---------------------------------------------\")\n",
    "for id, label in enumerate(data_train.target_names):\n",
    "    print(\"%-6d %-10s\" % (id, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cú chip đầu diễn ra ở hố 15 par4, khi Matsuyama đưa bóng vào bãi cỏ rough dày, cách lỗ khoảng 8,5 mét. Do anh nhẹ tay, bóng bay trước nhưng lại bị đầu gậy sắt bắt kịp. Vì thế, cựu vô địch major người Nhật Bản tình cờ có \"một cú hai chạm\". Dù vậy, bóng chỉ đến cách mục tiêu hơn ba mét. Từ đó, Matsuyama ghi bogey sau hai gạt.Cú chip thứ hai diễn ra tại hố 16 par5, dẫn đến eagle khi Matsuyama ra tay cách lỗ 15,2 mét. Nhờ vậy, anh lên điểm vòng -5. Khi Matsuyama ghi par cả hai hố còn lại, nó trở thành điểm giải cùng vị trí T2 cho anh. Đỉnh bảng thuộc về Shane Lowry ở mức -6.Kết quả vòng 1 của Matsuyama hẳn đã khác, nếu theo chiếu luật golf cũ khi anh chạm bóng hai lần trong cú chip tại hố 15. Trong tình huống như thế, luật từ 2018 trở về trước sẽ phạt hai gậy, còn hiện nay thì không.Matsuyama cũng không rõ sự thay đổi đó. \"Lúc ấy, tôi không biết mình bị phạt hay không. Sau khi caddie giải thích, tôi mới yên tâm đánh tiếp\", anh nói sau trận mở màn Arnold Palmer Invitational, trên sân Bay Hill par72 ở Orlando, Florida. Giải này thuộc diện đặc biệt (signature) trên PGA Tour 2024, với quỹ thưởng ở mức 20 triệu USD.Matsuyama, 32 tuổi, đấu chuyên nghiệp từ 2013. Anh đã qua 250 giải trên PGA Tour trong đó chín lần vô địch, tính cả major Masters 2021, còn tiền thưởng gộp đạt 48,53 triệu USD. Chiếc cup mới nhất vào tay anh hôm 18/2/2024, tại Genesis Invitational do Tiger Woods chủ trì, cũng trong nhóm signature trên đấu trường golf hạng nhất Mỹ mùa này.Quốc Huy\\r\\n', 'Đồ họa: Interesting Engineering\\r\\n']\n",
      "\n",
      "['data/news_vnexpress/the-thao\\\\00065.txt'\n",
      " 'data/news_vnexpress/khoa-hoc\\\\00040.txt']\n",
      "\n",
      "[8 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_train.data[0:2], end='\\n\\n')\n",
    "print(data_train.filenames[0:2], end='\\n\\n')\n",
    "print(data_train.target[0:2], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bài tập\\n - Kiểm tra các thông tin sau:\\n    + Số lượng văn bản trong data_train.data\\n    + Số lượng ids trong data_train.target\\n    + Số lượng filenames trong data_train.filenames\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Bài tập\n",
    " - Kiểm tra các thông tin sau:\n",
    "    + Số lượng văn bản trong data_train.data\n",
    "    + Số lượng ids trong data_train.target\n",
    "    + Số lượng filenames trong data_train.filenames\n",
    "\"\"\"\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tiền xử lý dữ liệu: đưa dữ liệu từ dạng text về dạng ma trận bằng TF-IDF\n",
    "\n",
    "- Thử nghiệm để kiểm tra hoạt động chuyển hoá dữ liệu về dạng ma trận "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số lượng từ dừng: 2063\n",
      "Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại):  ['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy']\n",
      "\n",
      "5 từ đầu tiên trong từ điển:\n",
      "\n",
      "1 :  ('cú', 3451)\n",
      "2 :  ('chip', 2799)\n",
      "3 :  ('đầu', 14289)\n",
      "4 :  ('diễn', 3858)\n",
      "5 :  ('hố', 6007)\n",
      "6 :  ('15', 146)\n",
      "\n",
      "Số chiều của dữ liệu: (1309, 14444)\n",
      "Số từ trong từ điển: 14444\n"
     ]
    }
   ],
   "source": [
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding='utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords]\n",
    "print(f\"Tổng số lượng từ dừng: {len(stopwords)}\")\n",
    "print(\"Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại): \", stopwords[:10])\n",
    "print()\n",
    "\n",
    "\"\"\"\n",
    "Chuyển hoá dữ liệu text về dạng vector tfidf \n",
    "    - loại bỏ từ dừng\n",
    "    - sinh từ điển\n",
    "    - chuyển thành dữ liệu dạng ma trận 2 chiều kích thước n x m với n là số lượng văn bản và m là số lượng từ trong từ điển\n",
    "\"\"\"\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords)\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ])\n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "print(\"5 từ đầu tiên trong từ điển:\\n\")\n",
    "i = 0\n",
    "for k,v in module_count_vector.vocabulary_.items():\n",
    "    i+=1\n",
    "    print(i, \": \", (k, v))\n",
    "    if i > 5:\n",
    "        break \n",
    "print()\n",
    "\n",
    "# Số chiều của dữ liệu \n",
    "print(f\"Số chiều của dữ liệu: {data_preprocessed.shape}\")\n",
    "print(f\"Số từ trong từ điển: {len(module_count_vector.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia dữ liệu thành 2 phần train_data và test_data\n",
    "- train_data chiếm 80 % dữ liệu \n",
    "- test_data chiếm 20 % dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu training =  (1047, 14444) (1047,)\n",
      "Dữ liệu testing =  (262, 14444) (262,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# chia dữ liệu thành 2 phần sử dụng hàm train_test_split.\n",
    "test_size = 0.2\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split( data_preprocessed, data_train.target, test_size=test_size)\n",
    "\n",
    "\n",
    "# hiển thị một số thông tin về dữ liệu \n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Hiển thị ra id, tên nhãn của 5 văn bản đầu tiên trong tập train. \n",
    " - Gợi ý: lấy dữ liệu id từ biến y_train, mapping với thứ tự nằm trong mảng data_train.target_names\n",
    "\"\"\"\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Huấn luyện mô hình SVM trên tập train_data\n",
    "\n",
    "Sử dụng thư viện sklearn để xây dựng mô hình \n",
    "- `svm.SVC(kernel='linear', C=1.0)`: chọn hàm nhân phân tách là linear, tham số C=1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training ...\n",
      "- Train size = (1047, 14444)\n",
      "- model - train complete\n"
     ]
    }
   ],
   "source": [
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"- model - train complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Đánh giá mô hình SVM trên tập test_data\n",
    "\n",
    "Thực hiện dự đoán nhãn cho từng văn bản trong tập test_data \n",
    "\n",
    "Độ đo đánh giá: \n",
    "> accuracy = tổng số văn bản dự đoán đúng  / tổng số văn bản có trong tập test_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Testing ...\n",
      "- Acc = 0.916030534351145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng model đã được huấn luyện để phán đoán 1 văn bản mới \n",
    "- Dữ liệu mới đến ở dạng dữ liệu thô => cần tiền xử lý dữ liệu về dạng dữ_liệu_ma_trận\n",
    "- Phán đoán bằng hàm model.predict(dữ_liệu_ma_trận) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4941)\t0.6624426101578174\n",
      "  (0, 2255)\t0.7491126672586028\n",
      "\n",
      "[8] the-thao\n"
     ]
    }
   ],
   "source": [
    "# tiền xử lý dữ liệu sử dụng module model_rf_preprocess. \n",
    "news = [\"Công_phượng ghi bàn cho đội_tuyển Việt_nam\"]\n",
    "preprocessed_news = model_rf_preprocess.transform(news)\n",
    "print(preprocessed_news, end='\\n\\n')\n",
    "# phán đoán nhãn\n",
    "pred = model.predict(preprocessed_news)\n",
    "print(pred, data_train.target_names[pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bài tập bổ sung: \n",
    "\n",
    "### 4.1 Thử nghiệm các tham số \n",
    "\n",
    "- Các tham số với giá trị khác nhau có thể ảnh hưởng để kết quả học \n",
    "- Cần thử nghiệm kỹ lượng để đưa ra kết quả khách quan: tham số C, kernel.\n",
    "    - Chọn mô hình với bộ tham số cho kết quả tốt nhất "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bài tập\n",
    " - Đánh giá các tham số của mô hình SVM: kernel, C\n",
    " - Gợi ý:\n",
    "     + Đầu tiên cố định C = 1.0 (có thể là giá trị khác), thay đổi kernel = {'linear', 'poly', 'rbf', 'sigmoid'}\n",
    "     + Với mỗi kernel chạy huấn luyện và đánh giá lại mô hình. Chọn kernel cho acc cao nhất.\n",
    "       Giả sử trong trường hợp này là linear\n",
    "     + Cố định kernel là linear, thay đổi C = {0.1, 1.0, 5.0, 10.0}\n",
    "     + Với mỗi giá trị C chạy huấn luện và đánh giá lại. Chọn C cho acc cao nhất.\n",
    "\"\"\"\n",
    "######################\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Phân loại số viết tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu training =  (1437, 64) (1437,)\n",
      "Dữ liệu testing =  (360, 64) (360,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "target = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, target, test_size=test_size)\n",
    "\n",
    "print(\"Dữ liệu training = \", X_train.shape, y_train.shape)\n",
    "print(\"Dữ liệu testing = \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training ...\n",
      "- Train size = (1437, 64)\n",
      "- model - train complete\n",
      "- Testing ...\n",
      "- Acc = 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Bài tập\n",
    " - Đánh giá các tham số của mô hình SVM với bài toán phân loại ảnh\n",
    " - Gợi ý: Làm tương tự với phân loại văn bản phía trên\n",
    "\"\"\"\n",
    "######################\n",
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train.shape))\n",
    "model = svm.SVC(kernel='linear', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"- model - train complete\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"- Testing ...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
